<div id="module0">
<ul class="news-list" id="news-list">
	<li>[Apr. 2025]
		One paper accepted to Pattern Recognition: Low-redundancy Distillation for Continual Learning. Congrats Ruiqi!
	</li>

	<li>[Apr. 2025]
		One paper accepted to CVPR 2025: Multi-party Collaborative Attention Control for Image Customization. Congrats Han!
	</li>

	<li>[Jan. 2025]
		One paper accepted to ISCAS 2025: Classification-Based False Alarm Suppression for SAR Target Detection. Congrats Nan!
	</li>

	<li class="more-news" style="display:none;">[Dec. 2024]
		Three papers accepted to AAAI 2025:
		(1) MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models, 
		(2) Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition,
		(3) HSRDiff: A Hierarchical Self-Regulation Diffusion Model for Stochastic Semantic Segmentation.
		Congrats Chuanguang (& Xinqiang), Weilun, and Han!
	</li>

	<li class="more-news" style="display:none;">[Dec. 2024]
		Two papers accepted to ICASSP 2025:
		(1) IOR: Inversed Objects Replay for Incremental Object Detection,
		(2) OLN++: Improved Object Localization Network for Open-world Object Detection.
		Congrats Zijia and Haonan!
	</li>

	<li class="more-news" style="display:none;">[Sep. 2024]
		One paper accepted to NeurIPS 2024: Continual Learning in the Frequency Domain. Congrats Ruiqi!
	</li>

	<li class="more-news" style="display:none;">[Aug. 2024]
		One paper accepted to Cognitive Computation: PDD: Pruning Neural Networks During Knowledge Distillation!
	</li>
	
	<li class="more-news" style="display:none;">[May. 2024]
		One survey paper accepted to IEEE Transactions on Neural Networks and Learning Systems: A Survey on Causal Reinforcement Learning.
	</li>

	<li class="more-news" style="display:none;">[Feb. 2024]
		One paper accepted to ICLR 2024: KFC: Knowledge Reconstruction and Feedback Consolidation Enable Efficient and Effective Continual Generative Learning.
	</li>

	<li class="more-news" style="display:none;">[Jan. 2024]
		Two papers accepted to CSCWD 2024: (1) Online Relational Knowledge Distillation for Image Classification, (2) Class-wise Image Mixture Guided Self-Knowledge Distillation  for Image Classification.
	</li>
	
	<li class="more-news" style="display:none;">[Dec. 2023]
		获中国科学院计算技术研究所2023年度“优秀研究人员”。
	</li>

	<li class="more-news" style="display:none;">[Dec. 2023]
		获<a target="_blank" href="https://iacc.pazhoulab-huangpu.com/contest/">第二届粤港澳大湾区（黄埔）国际算法算例大赛“序列任务的持续学习”</a>殿军（4/725）。
	</li>

	<li class="more-news" style="display:none;">[Dec. 2023]
		One paper accepted to AAAI 2024: eTag: Class-Incremental Learning via Embedding Distillation and Task-Oriented Generation.
	</li>

	<li class="more-news" style="display:none;">[Dec. 2023]
		One paper accepted to IEEE Transactions on Biomedical Engineering: Automatic Spike Sorting with Low-Rank and Sparse Representation.
	</li>





</ul>
	<button id="more-news-btn" class="more-button"> More News <i class="fas fa-chevron-down"></i></button>
</div>
